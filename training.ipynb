{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Image Classification Part Two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import ImageFile, Image\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def load_process_images(img_path, target_size=(224,224)):\n",
    "  \n",
    "  try:\n",
    "    with Image.open(img_path) as image:\n",
    "      image = image.resize(target_size)\n",
    "      image = image.convert(\"RGB\")\n",
    "      \n",
    "      img_array = np.array(image)/255.0\n",
    "      img_array = img_array.astype(np.float32)\n",
    "      \n",
    "      return img_array\n",
    "  except IOError as e:\n",
    "    print(f\"Error loading image: {e}\")\n",
    "    return None\n",
    "\n",
    "def grab_images(PATH):\n",
    "  images, labels = [], []\n",
    "  for root, dir, files in os.walk(PATH):\n",
    "    for file in files:\n",
    "      if file.lower().endswith((\".png\", \".jpeg\", \".jpg\")):\n",
    "        file_path = os.path.join(root, file)\n",
    "        img = load_process_images(file_path)\n",
    "        if img is not None:\n",
    "          images.append(img)\n",
    "          label = root.split(os.sep)[-1]\n",
    "          labels.append(label)\n",
    "  \n",
    "  images, labels = np.array(images), np.array(labels)\n",
    "  \n",
    "  return images, labels\n",
    "\n",
    "def create_model(n_classes):\n",
    "  \n",
    "  model = Sequential([\n",
    "    Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(256, (3,3), activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(n_classes, activation=\"softmax\")\n",
    "  ])\n",
    "  \n",
    "  model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    "  )\n",
    "  model.summary()\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/maukanmir/Downloads/dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = grab_images(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_int = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_int, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4116\n",
      "Validation set size: 1373\n",
      "Test set size: 1373\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Validation set size: {X_val.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "  rotation_range=40,\n",
    "  width_shift_range=0.2,\n",
    "  height_shift_range=0.2,\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    "  horizontal_flip=True,\n",
    "  fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "  X_train, y_train,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow(\n",
    "  X_val, y_val,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow(\n",
    "  X_test, y_test,\n",
    "  batch_size=BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
